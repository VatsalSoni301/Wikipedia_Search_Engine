{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import xml.etree.cElementTree as et\n",
    "import pickle\n",
    "import base64\n",
    "from collections import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "stop_words = {}\n",
    "stop_file = open(\"stop_words.txt\", \"r\")\n",
    "words = stop_file.read()\n",
    "words = words.split(\",\")\n",
    "for word in words:\n",
    "    word = word.strip()\n",
    "    if word:\n",
    "        stop_words[word[1:-1]] = 1\n",
    "# print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"[^a-zA-Z]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments = sys.argv\n",
    "# wikipedia_dump = arguments[0]\n",
    "wikipedia_dump = \"/home/vatsal/Documents/IIIT/Sem-3/IRE/wikipedia/wiki.xml\"\n",
    "content = et.iterparse(wikipedia_dump, events=(\"start\", \"end\"))\n",
    "content = iter(content)\n",
    "# document_title = open(\"index/document_title.pickle\", \"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_inverted_index = defaultdict(list)\n",
    "body_inverted_index = defaultdict(list)\n",
    "category_inverted_index = defaultdict(list)\n",
    "infobox_inverted_index = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_no = 0\n",
    "title_freq = {}\n",
    "body_freq = {}\n",
    "category_freq = {}\n",
    "infobox_freq = {}\n",
    "document_title = {}\n",
    "document_word = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event,context in content:\n",
    "    tag = re.sub(r\"{.*}\", \"\", context.tag)\n",
    "    \n",
    "    if event == \"end\":\n",
    "        \n",
    "        if tag == \"title\":\n",
    "            \n",
    "            title_text = context.text\n",
    "            document_title[document_no]=title_text\n",
    "            title_text = title_text.lower()\n",
    "            try:\n",
    "                words = re.split(pattern, title_text)\n",
    "                for word in words:\n",
    "                    word = stemmer.stem(word)\n",
    "                    if word and word not in stop_words:\n",
    "                        if word not in title_freq:\n",
    "                            title_freq[word] = 1\n",
    "                        else:\n",
    "                            title_freq[word] += 1\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        elif tag == \"text\":\n",
    "            \n",
    "            try:\n",
    "                body_text = context.text\n",
    "                category_words = re.findall(\"\\[\\[Category:(.*?)\\]\\]\", body_text);\n",
    "                if category_words != \"\":\n",
    "                    for category_word in category_words:\n",
    "                        words = re.split(pattern, category_word)\n",
    "                        for word in words:\n",
    "                            word = stemmer.stem(word.lower())\n",
    "                            if  word and word not in stop_words:\n",
    "                                if word not in category_freq:\n",
    "                                    category_freq[word] = 1\n",
    "                                else:\n",
    "                                    category_freq[word] += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                info_words = re.findall(\"{{Infobox(.*?)}}\", body_text)\n",
    "                if info_words != \"\":\n",
    "                    for info_word in info_words:\n",
    "                        words = re.split(pattern, info_word)\n",
    "                        for word in words:\n",
    "                            word = stemmer.stem(word.lower())\n",
    "                            if word and word not in stop_words:\n",
    "                                if word not in infobox_freq:\n",
    "                                    infobox_freq[word] = 1\n",
    "                                else:\n",
    "                                    infobox_freq[word] += 1\n",
    "            except:\n",
    "                pass\n",
    "                                    \n",
    "            try:\n",
    "                words = re.split(pattern, body_text)\n",
    "\n",
    "                for word in words:\n",
    "                    word = stemmer.stem(word.lower())\n",
    "                    if word and word not in stop_words:\n",
    "                        if word not in body_freq:\n",
    "                            body_freq[word] = 1\n",
    "                        else:\n",
    "                            body_freq[word] += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        elif tag == \"page\":\n",
    "            d_no = str(document_no)\n",
    "            for word in body_freq:\n",
    "                body_inverted_index[word].append(d_no + \":\" + str(body_freq[word]))\n",
    "            \n",
    "            body_freq = {}\n",
    "\n",
    "            for word in title_freq:\n",
    "                title_inverted_index[word].append(d_no + \":\" + str(title_freq[word]))\n",
    "            \n",
    "            title_freq = {}\n",
    "\n",
    "            for word in category_freq:\n",
    "                category_inverted_index[word].append(d_no + \":\" + str(category_freq[word]))\n",
    "            \n",
    "            category_freq = {}\n",
    "\n",
    "            for word in infobox_freq:\n",
    "                infobox_inverted_index[word].append(d_no + \":\" + str(infobox_freq[word]))\n",
    "            \n",
    "            infobox_freq = {}\n",
    "                \n",
    "            document_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"index/title.txt\"\n",
    "title_file = open(filename, \"w+\")\n",
    "pointer = 0\n",
    "for word in sorted(title_inverted_index) :\n",
    "    posting_list = \",\".join(title_inverted_index[word])\n",
    "    index = word + \"-\" + posting_list + \"\\n\"\n",
    "    document_word[word] = {}\n",
    "    document_word[word]['t'] = pointer\n",
    "    title_file.write(index)\n",
    "    pointer += len(index)\n",
    "title_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"index/category.txt\"\n",
    "category_file = open(filename, \"w+\")\n",
    "pointer = 0\n",
    "for word in sorted(category_inverted_index) :\n",
    "    posting_list = \",\".join(category_inverted_index[word])\n",
    "    index = word + \"-\" + posting_list + \"\\n\"\n",
    "    if word not in document_word:\n",
    "        document_word[word] = {}\n",
    "    document_word[word]['c'] = pointer\n",
    "    category_file.write(index)\n",
    "    pointer += len(index)\n",
    "category_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"index/infobox.txt\"\n",
    "infobox_file = open(filename, \"w+\")\n",
    "pointer = 0\n",
    "for word in sorted(infobox_inverted_index) :\n",
    "    posting_list = \",\".join(infobox_inverted_index[word])\n",
    "    index = word + \"-\" + posting_list + \"\\n\"\n",
    "    if word not in document_word:\n",
    "        document_word[word] = {}\n",
    "    document_word[word]['i'] = pointer\n",
    "    infobox_file.write(index)\n",
    "    pointer += len(index)\n",
    "infobox_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"index/body_text.txt\"\n",
    "body_text_file = open(filename, \"w+\")\n",
    "pointer = 0\n",
    "for word in sorted(body_inverted_index) :\n",
    "    posting_list = \",\".join(body_inverted_index[word])\n",
    "    index = word + \"-\" + posting_list + \"\\n\"\n",
    "    if word not in document_word:\n",
    "        document_word[word] = {}\n",
    "    document_word[word]['b'] = pointer\n",
    "    body_text_file.write(index)\n",
    "    pointer += len(index)\n",
    "body_text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"index/title_doc_no.pickle\", \"wb\")\n",
    "pickle.dump(document_title, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"index/word_position.pickle\", \"wb\")\n",
    "pickle.dump(document_word, file)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
