{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import xml.etree.cElementTree as et\n",
    "import pickle\n",
    "import base64\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "stop_words = {}\n",
    "stop_file = open(\"stop_words.txt\", \"r\")\n",
    "words = stop_file.read()\n",
    "words = words.split(\",\")\n",
    "for word in words:\n",
    "    word = word.strip()\n",
    "    if word:\n",
    "        stop_words[word[1:-1]] = 1\n",
    "# print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"[^a-zA-Z0-9]\")\n",
    "cssExp = re.compile(r'{\\|(.*?)\\|}',re.DOTALL)\n",
    "linkExp = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments = sys.argv\n",
    "# wikipedia_dump = arguments[0]\n",
    "wikipedia_dump = \"/home/vatsal/Documents/IIIT/Sem-3/IRE/wikipedia/wiki.xml\"\n",
    "content = et.iterparse(wikipedia_dump, events=(\"start\", \"end\"))\n",
    "content = iter(content)\n",
    "# document_title = open(\"index/document_title.pickle\", \"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_inverted_index = {}\n",
    "body_inverted_index = {}\n",
    "category_inverted_index = {}\n",
    "infobox_inverted_index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_no = 0\n",
    "title_freq = {}\n",
    "body_freq = {}\n",
    "category_freq = {}\n",
    "infobox_freq = {}\n",
    "document_title = {}\n",
    "document_word = {}\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_into_file(filename,inverted_object,flag):\n",
    "    global document_word\n",
    "    fileptr = open(filename, \"w+\")\n",
    "    pointer = 0\n",
    "    for word in inverted_object:\n",
    "        posting_list = \",\".join(inverted_object[word])\n",
    "        posting_list = posting_list + \"\\n\"\n",
    "        if word not in document_word:\n",
    "            document_word[word] = {}\n",
    "        document_word[word][flag] = pointer\n",
    "        fileptr.write(posting_list)\n",
    "        pointer += len(posting_list)\n",
    "    fileptr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pickle_file(filename, pickleobj):\n",
    "    file = open(filename, \"wb\")\n",
    "    pickle.dump(pickleobj, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event,context in content:\n",
    "    tag = re.sub(r\"{.*}\", \"\", context.tag)\n",
    "    \n",
    "    if event == \"end\":\n",
    "        \n",
    "        if tag == \"title\":\n",
    "            \n",
    "            title_text = context.text\n",
    "            document_title[document_no]=title_text\n",
    "            title_text = title_text.lower()\n",
    "            try:\n",
    "                words = re.split(pattern, title_text)\n",
    "                for word in words:\n",
    "#                     word=word.strip()\n",
    "                    word = stemmer.stem(word)\n",
    "                    if len(word) <= 2:\n",
    "                        continue\n",
    "                    if word and word not in stop_words:\n",
    "                        if word not in title_freq:\n",
    "                            title_freq[word] = 1\n",
    "                        else:\n",
    "                            title_freq[word] += 1\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        elif tag == \"text\":\n",
    "            \n",
    "            body_text = context.text\n",
    "            body_text = linkExp.sub('',str(body_text))\n",
    "            body_text = cssExp.sub('',str(body_text))\n",
    "            try:\n",
    "                category_words = re.findall(\"\\[\\[Category:(.*?)\\]\\]\", body_text);\n",
    "                if category_words != \"\":\n",
    "                    for category_word in category_words:\n",
    "                        words = re.split(pattern, category_word)\n",
    "                        for word in words:\n",
    "#                             word=word.strip()\n",
    "                            word = stemmer.stem(word.lower())\n",
    "                            if len(word) <= 2:\n",
    "                                continue\n",
    "                            if  word and word not in stop_words:\n",
    "                                if word not in category_freq:\n",
    "                                    category_freq[word] = 1\n",
    "                                else:\n",
    "                                    category_freq[word] += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "\n",
    "                info_words = re.findall(\"{{Infobox((.|\\n)*?)}}\", body_text)\n",
    "                if info_words != \"\":\n",
    "                    for info_word in info_words:\n",
    "                        for i_word in info_word:\n",
    "                            words = re.split(pattern, i_word)\n",
    "                            for word in words:\n",
    "#                                 word=word.strip()\n",
    "                                word = stemmer.stem(word.lower())\n",
    "                                if len(word) <= 2:\n",
    "                                    continue\n",
    "                                if word and word not in stop_words:\n",
    "                                    if word not in infobox_freq:\n",
    "                                        infobox_freq[word] = 1\n",
    "                                    else:\n",
    "                                        infobox_freq[word] += 1\n",
    "            except:\n",
    "                pass\n",
    "                                    \n",
    "            try:\n",
    "                words = re.split(pattern, body_text)\n",
    "\n",
    "                for word in words:\n",
    "                    word = stemmer.stem(word.lower())\n",
    "                    if len(word) <= 2:\n",
    "                        continue\n",
    "                    if word and word not in stop_words:\n",
    "                        if word not in body_freq:\n",
    "                            body_freq[word] = 1\n",
    "                        else:\n",
    "                            body_freq[word] += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        elif tag == \"page\":\n",
    "            d_no = str(document_no)\n",
    "            for word in body_freq:\n",
    "                if word not in body_inverted_index:\n",
    "                    body_inverted_index[word]=[]\n",
    "                body_inverted_index[word].append(d_no + \":\" + str(body_freq[word]))\n",
    "            \n",
    "            body_freq = {}\n",
    "\n",
    "            for word in title_freq:\n",
    "                if word not in title_inverted_index:\n",
    "                    title_inverted_index[word]=[]\n",
    "                title_inverted_index[word].append(d_no + \":\" + str(title_freq[word]))\n",
    "            \n",
    "            title_freq = {}\n",
    "\n",
    "            for word in category_freq:\n",
    "                if word not in category_inverted_index:\n",
    "                    category_inverted_index[word]=[]\n",
    "                category_inverted_index[word].append(d_no + \":\" + str(category_freq[word]))\n",
    "            \n",
    "            category_freq = {}\n",
    "\n",
    "            for word in infobox_freq:\n",
    "                if word not in infobox_inverted_index:\n",
    "                    infobox_inverted_index[word]=[]\n",
    "                infobox_inverted_index[word].append(d_no + \":\" + str(infobox_freq[word]))\n",
    "            \n",
    "            infobox_freq = {}\n",
    "                \n",
    "            document_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"index/title.txt\"\n",
    "write_into_file(filename,title_inverted_index,'t')\n",
    "filename = \"index/category.txt\"\n",
    "write_into_file(filename,category_inverted_index,'c')\n",
    "filename = \"index/infobox.txt\"\n",
    "write_into_file(filename,infobox_inverted_index,'i')\n",
    "filename = \"index/body_text.txt\"\n",
    "write_into_file(filename,body_inverted_index,'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"index/word_position.pickle\"\n",
    "write_pickle_file(filename, document_word)\n",
    "filename = \"index/title_doc_no.pickle\"\n",
    "write_pickle_file(filename, document_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(\"Time Taken :- \",(end-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
