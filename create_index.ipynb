{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import xml.etree.cElementTree as et\n",
    "import pickle\n",
    "import base64\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "stop_words = {}\n",
    "stop_file = open(\"stop_words.txt\", \"r\")\n",
    "words = stop_file.read()\n",
    "words = words.split(\",\")\n",
    "for word in words:\n",
    "    word = word.strip()\n",
    "    if word:\n",
    "        stop_words[word[1:-1]] = 1\n",
    "# print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"[^a-zA-Z0-9]\")\n",
    "cssExp = re.compile(r'{\\|(.*?)\\|}',re.DOTALL)\n",
    "linkExp = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments = sys.argv\n",
    "# wikipedia_dump = arguments[0]\n",
    "wikipedia_dump = \"/home/vatsal/Documents/IIIT/Sem-3/IRE/wikipedia/wiki.xml\"\n",
    "content = et.iterparse(wikipedia_dump, events=(\"start\", \"end\"))\n",
    "content = iter(content)\n",
    "# document_title = open(\"index/document_title.pickle\", \"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_inverted_index = {}\n",
    "body_inverted_index = {}\n",
    "category_inverted_index = {}\n",
    "infobox_inverted_index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_no = 0\n",
    "title_freq = {}\n",
    "body_freq = {}\n",
    "category_freq = {}\n",
    "infobox_freq = {}\n",
    "document_title = {}\n",
    "document_word = {}\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event,context in content:\n",
    "    tag = re.sub(r\"{.*}\", \"\", context.tag)\n",
    "    \n",
    "    if event == \"end\":\n",
    "        \n",
    "        if tag == \"title\":\n",
    "            \n",
    "            title_text = context.text\n",
    "            document_title[document_no]=title_text\n",
    "            title_text = title_text.lower()\n",
    "            try:\n",
    "                words = re.split(pattern, title_text)\n",
    "                for word in words:\n",
    "#                     word=word.strip()\n",
    "                    word = stemmer.stem(word)\n",
    "                    if len(word) <= 2:\n",
    "                        continue\n",
    "                    if word and word not in stop_words:\n",
    "                        if word not in title_freq:\n",
    "                            title_freq[word] = 1\n",
    "                        else:\n",
    "                            title_freq[word] += 1\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        elif tag == \"text\":\n",
    "            \n",
    "            body_text = context.text\n",
    "            body_text = linkExp.sub('',str(body_text))\n",
    "            body_text = cssExp.sub('',str(body_text))\n",
    "            try:\n",
    "                category_words = re.findall(\"\\[\\[Category:(.*?)\\]\\]\", body_text);\n",
    "                if category_words != \"\":\n",
    "                    for category_word in category_words:\n",
    "                        words = re.split(pattern, category_word)\n",
    "                        for word in words:\n",
    "#                             word=word.strip()\n",
    "                            word = stemmer.stem(word.lower())\n",
    "                            if len(word) <= 2:\n",
    "                                continue\n",
    "                            if  word and word not in stop_words:\n",
    "                                if word not in category_freq:\n",
    "                                    category_freq[word] = 1\n",
    "                                else:\n",
    "                                    category_freq[word] += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "\n",
    "                info_words = re.findall(\"{{Infobox((.|\\n)*?)}}\", body_text)\n",
    "                if info_words != \"\":\n",
    "                    for info_word in info_words:\n",
    "                        for i_word in info_word:\n",
    "                            words = re.split(pattern, i_word)\n",
    "                            for word in words:\n",
    "#                                 word=word.strip()\n",
    "                                word = stemmer.stem(word.lower())\n",
    "                                if len(word) <= 2:\n",
    "                                    continue\n",
    "                                if word and word not in stop_words:\n",
    "                                    if word not in infobox_freq:\n",
    "                                        infobox_freq[word] = 1\n",
    "                                    else:\n",
    "                                        infobox_freq[word] += 1\n",
    "            except:\n",
    "                pass\n",
    "                                    \n",
    "            try:\n",
    "                words = re.split(pattern, body_text)\n",
    "\n",
    "                for word in words:\n",
    "                    word = stemmer.stem(word.lower())\n",
    "                    if len(word) <= 2:\n",
    "                        continue\n",
    "                    if word and word not in stop_words:\n",
    "                        if word not in body_freq:\n",
    "                            body_freq[word] = 1\n",
    "                        else:\n",
    "                            body_freq[word] += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        elif tag == \"page\":\n",
    "            d_no = str(document_no)\n",
    "            for word in body_freq:\n",
    "                if word not in body_inverted_index:\n",
    "                    body_inverted_index[word]=[]\n",
    "                body_inverted_index[word].append(d_no + \":\" + str(body_freq[word]))\n",
    "            \n",
    "            body_freq = {}\n",
    "\n",
    "            for word in title_freq:\n",
    "                if word not in title_inverted_index:\n",
    "                    title_inverted_index[word]=[]\n",
    "                title_inverted_index[word].append(d_no + \":\" + str(title_freq[word]))\n",
    "            \n",
    "            title_freq = {}\n",
    "\n",
    "            for word in category_freq:\n",
    "                if word not in category_inverted_index:\n",
    "                    category_inverted_index[word]=[]\n",
    "                category_inverted_index[word].append(d_no + \":\" + str(category_freq[word]))\n",
    "            \n",
    "            category_freq = {}\n",
    "\n",
    "            for word in infobox_freq:\n",
    "                if word not in infobox_inverted_index:\n",
    "                    infobox_inverted_index[word]=[]\n",
    "                infobox_inverted_index[word].append(d_no + \":\" + str(infobox_freq[word]))\n",
    "            \n",
    "            infobox_freq = {}\n",
    "                \n",
    "            document_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"index/title.txt\"\n",
    "title_file = open(filename, \"w+\")\n",
    "pointer = 0\n",
    "for word in sorted(title_inverted_index) :\n",
    "    posting_list = \",\".join(title_inverted_index[word])\n",
    "    posting_list = posting_list + \"\\n\"\n",
    "    document_word[word] = {}\n",
    "    document_word[word]['t'] = pointer\n",
    "    title_file.write(posting_list)\n",
    "    pointer += len(posting_list)\n",
    "title_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"index/category.txt\"\n",
    "category_file = open(filename, \"w+\")\n",
    "pointer = 0\n",
    "for word in sorted(category_inverted_index) :\n",
    "    posting_list = \",\".join(category_inverted_index[word])\n",
    "    posting_list = posting_list + \"\\n\"\n",
    "    if word not in document_word:\n",
    "        document_word[word] = {}\n",
    "    document_word[word]['c'] = pointer\n",
    "    category_file.write(posting_list)\n",
    "    pointer += len(posting_list)\n",
    "category_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"index/infobox.txt\"\n",
    "infobox_file = open(filename, \"w+\")\n",
    "pointer = 0\n",
    "for word in sorted(infobox_inverted_index) :\n",
    "    posting_list = \",\".join(infobox_inverted_index[word])\n",
    "    posting_list = posting_list + \"\\n\"\n",
    "    if word not in document_word:\n",
    "        document_word[word] = {}\n",
    "    document_word[word]['i'] = pointer\n",
    "    infobox_file.write(posting_list)\n",
    "    pointer += len(posting_list)\n",
    "infobox_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"index/body_text.txt\"\n",
    "body_text_file = open(filename, \"w+\")\n",
    "pointer = 0\n",
    "for word in sorted(body_inverted_index) :\n",
    "    posting_list = \",\".join(body_inverted_index[word])\n",
    "    posting_list = posting_list + \"\\n\"\n",
    "    if word not in document_word:\n",
    "        document_word[word] = {}\n",
    "    document_word[word]['b'] = pointer\n",
    "    body_text_file.write(posting_list)\n",
    "    pointer += len(posting_list)\n",
    "body_text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"index/title_doc_no.pickle\", \"wb\")\n",
    "pickle.dump(document_title, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"index/word_position.pickle\", \"wb\")\n",
    "pickle.dump(document_word, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken :-  202.48847889900208\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(\"Time Taken :- \",(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
